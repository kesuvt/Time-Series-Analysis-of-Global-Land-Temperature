# -*- coding: utf-8 -*-
"""B00912328_AkshayKumar_VT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i_BpieG8bMPAPRgzBoH-jlUzjQwkmbrg

***Time Series Analysis of Global Land Temperature Data***

GlobalLandTemperature data contains country-wise monthly average land temperature from November 1743 to September 2013. It has 4 variables: 'Date','Averagetemperature','AverageTemperatureUncertainty' and 'Country' and 577462 data points.

The aim of this analysis is to build a time series model to forecast the land temperatures for the countries namely, USA, UK, Brazil, Kenya and India. ARIMA model is being used here for the purpose.

The data from January 1900 to December 2010 will be taken as the training set and from 2011 to 2013 will be taken as the test data

**1. Setting up the environment**

1.   Installing seabron
2.   Checking the version of python
3.   Import necessary libraries
"""

# Installing seaborn (seaborn is a visualization library for python)
!pip install seaborn
# Installing pydrive
!pip install -U -q PyDrive

# Check the version of Python
!python --version

# Import necessary libraries
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import itertools
from statsmodels.tsa.stattools import adfuller,acf, pacf
from statsmodels.tsa.arima.model import ARIMA
import statsmodels.api as sm
from pylab import rcParams
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf,plot_predict
from sklearn import metrics
from sklearn.metrics import mean_squared_error

"""2) Loading and understanding the dataset

1. Authenticating a Google Drive client to download the file   
2. Downloading the data
3. Reading the file using pandas
4. Understanding the dataset
"""

# Authenticate and create the PyDrive client
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

file_list = drive.ListFile({'q': "'1WEWMdTfmeKD-tFrXrOlTtFkKhnoL_fU6' in parents"}).GetList()
for f in file_list:
  print('title: %s, id: %s' % (f['title'], f['id']))

id='13bxB3TO8Q8yK3qxAQql_Sltm1npK7yZJ'
downloaded = drive.CreateFile({'id': id})
downloaded.GetContentFile('GlobalLandTemperaturesByCountry.csv')

# Import the CSV file
df = pd.read_csv('/content/GlobalLandTemperaturesByCountry.csv')

# View the different variables and first 5 entries
df.head()
# How many data points are there?
df.count()
# Describe the data frame
df.describe()
#Finding more info like data types and columns
df.info()

"""*   There are 577462 data points and 4 variables
*   The data type of 'dt' column which has date, is object as of now. which needs to be rectified while cleaning
*   From df.head(), it is clear that there are missing values in the data. The data will be checked for missing values again after filtering the data as per requirement
*   From the data description, the variable of interest i.e. 'Averagetemperature' has a minimum value of -37.65 and a maximum value of 38.84 with a mean of 17.19 (unit of measurement is degree celsius)

**3) Initial cleaning process as per the requirements**
"""

# 1) Changing the type of "dt" column from "object" to "date"
df['dt'] = pd.to_datetime(df['dt'], infer_datetime_format=True)
#Checking the type again to confirm
df.info()

# 2.1) Filtering based on Date (According to the instructions in the coursework spec.)
filteredDf = df[(df.dt > '1899-12-01')]
filteredDf.count()
# 2.2) Filtering based on Countries (According to the instructions in the coursework spec.)
filteredDf = filteredDf[filteredDf["Country"].isin(['United States','United Kingdom','Brazil','Kenya','India'])]


filteredDf.head()
filteredDf.count()

"""The data of our interest i.e. average temperature from January 1900 to September 2013 for the countries USA, UK, brazil, Kenya and India has a total of 6825 data points."""

# 3)Finding missing and unique values
print("Features: \n", filteredDf.columns)
print("\nAny Missing values - : \n", filteredDf.isnull().any())
print("\nUnique Values: \n", filteredDf.nunique())

"""Even the filtered data contains missing values in them. In the next step, the data will be split country-wise and figure out if missing values are a big issue for each of them"""

#Filtering the data for the countries USA, UK, Brazil, kenya, India
#USA
USA_df = filteredDf[filteredDf['Country'] == 'United States']
USA_df.head()
USA_df.count()
print("\nAny Missing values - : \n", USA_df.isnull().any())
#UK
UK_df = filteredDf[filteredDf['Country'] == "United Kingdom"]
UK_df.head()
print("\nAny Missing values - : \n", UK_df.isnull().any())
UK_df.count()
#Brazil
Brazil_df = filteredDf[filteredDf['Country'] == "Brazil"]
Brazil_df.head()
print("\nAny Missing values - : \n", Brazil_df.isnull().any())
Brazil_df.count()
#Kenya
Kenya_df = filteredDf[filteredDf['Country'] == "Kenya"]
Kenya_df.head()
print("\nAny Missing values - : \n", Brazil_df.isnull().any())
Kenya_df.count()
#India
India_df = filteredDf[filteredDf['Country'] == "India"]
India_df.head()
print("\nAny Missing values - : \n", Brazil_df.isnull().any())
India_df.count()

"""USA has no missing values and the opther countries have one missing value each. So, missing value isn't going to be a major issue in this analysis

**4) Time series components (USA)**

In this section, the time series components of the data will be analysed. For convenience, this will be done in a for loop for all five countries
1.   Trend  
2.   Seasonality
"""

# 1) Trend
data_list = [USA_df,UK_df, Brazil_df, Kenya_df, India_df]
title_list = ['USA','UK','Brazil','Kenya','India']
for (i,j) in zip(data_list,title_list):
  plt.figure(figsize= (50,20))
  plt.plot(i['dt'],i['AverageTemperature'])
  plt.xlabel('Time')
  plt.ylabel('Monthly Average temperature')
  plt.title('Average Temperature of %s' %j, fontsize=30)

"""There is very small or no upward  trend in the data with time for USA, UK and India. There is visible trend in the plot for the countries Brazil and Kenya. But, there is visible seasonality in the data for all countries. So as a next step, we will try to visualize the seasonality component of the data."""

data_list = [USA_df, UK_df, Brazil_df, Kenya_df, India_df]
title_list = ['USA','UK','Brazil','Kenya','India']
for (i,j) in zip(data_list,title_list):
  # To plot the seasonality we are going to create a temp dataframe and add columns for Month and Year values
  df_temp = i.copy()
  # Then convert the 'dt' variable to string type for easier slicing
  df_temp['dt'] = df_temp['dt'].astype(str)
  df_temp['Year'] = df_temp['dt'].str[0:4]
  df_temp['Month'] = df_temp['dt'].str[5:7]
  # Seaborn library is used to plot the seasonality of the data
  plt.figure(figsize=(75,25))
  plt.title('Seasonality of %s Average Temperature' %j, fontsize=30)
  sns.pointplot(x='Month',y='AverageTemperature',hue='Year',data=df_temp)

"""Seasonality is similar in the USA and the UK average temperature with lowest temperatures during Nov-Feb period (Winter) and highest average temperatures during June-Sep period (Summer). For the rest of the countries, seasonality is a bit different.

In Brazil, summer seems to be from December to March and winter is from May to September. This is because the country is in the southern hemisphere and the weather there would be more or less reverse of that of northern hemisphere.

In Kenya, the lowest average temperature is between June and September and the highest is between February and April. This is consistent with the weather in Kenya where the winter runs from July to october and the long rainy season runs from April to June.

Seasonality in Indian temperature data is more or less similar to that of the USA and the UK, except for the small dip in temperature during July-September period. This is consistent with the monsoon season during this period in India.

**5) Checking for stationarity**

ARIMA model can only be fit on a stationary data, i.e. a time series data which has no recurring time dependent features. So, the data needs to be checked for stationarity before proceeding further.
This is done via Augmented dickey-Fuller test. This test has a null hypothesis : the time series data is non-stationary. So, if the p-value is less than the critical value (0.05) then we can reject the null hypothesis.
"""

data_list = [USA_df,UK_df, Brazil_df, Kenya_df, India_df]
title_list = ['USA','UK','Brazil','Kenya','India']
for (i,j) in zip(data_list,title_list):
  print('ADF Test for %s' %j)
  dftest = adfuller(i['AverageTemperature'].dropna())
  df_output = pd.Series(dftest[0:4], index = ['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])
  for key, value in dftest[4].items():
    df_output['Critical Value (%s)' %key] = value
  print(df_output)

"""since critical p value < 0.05 for the countries USA, UK and india, we can reject the null hypothesis in these cases i.e. the data is stationary for these countries. But, for Brazil and Kenya, p-value is greater than 0.05, so the data is non-stationary and they will need to be converted to stationary

**5.1) Converting the non-stationary data into stationary (Brazil)**

First step is transforming the data using differencing. This is done by diff(). First, first order will be done and try the ADF test, and if required, it will be done again
"""

# Brazil data
Brazil_df_diff = Brazil_df['AverageTemperature'].diff(periods = 1)
plt.figure(figsize= (50,20))
plt.xlabel('Years', fontsize = 25)
plt.ylabel('Average temperature', fontsize = 25)
plt.title('Convert Non Stationary Data to Stationary Data using Differencing ', fontsize=30)
plt.plot(Brazil_df_diff)

"""trend in the Brazil_df has been removed by first order differencing. In the next step, adf test will be repeated to test the effectiveness of differencing technique"""

dftest = adfuller(Brazil_df_diff.dropna())
df_output = pd.Series(dftest[0:4], index = ['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])
for key, value in dftest[4].items():
  df_output['Critical Value (%s)' %key] = value
print(df_output)

"""P- value now is much less than 0.05 which means the current data is now stationary

**5.2) Converting the non-stationary data into stationary (Kenya)**
"""

# Kenya data
Kenya_df_diff = Kenya_df['AverageTemperature'].diff(periods = 1)
plt.figure(figsize= (50,20))
plt.xlabel('Years', fontsize =25)
plt.ylabel('Average temperature', fontsize =25)
plt.title('Convert Non Stationary Data to Stationary Data using Differencing ', fontsize = 30)
plt.plot(Kenya_df_diff)

"""Repeating the adf test to check the effectiveness of the differencing technique"""

dftest = adfuller(Kenya_df_diff.dropna())
df_output = pd.Series(dftest[0:4], index = ['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])
for key, value in dftest[4].items():
  df_output['Critical Value (%s)' %key] = value
print(df_output)

"""P- value now is much less than 0.05 which means the current data is now stationary

**6) ACF and PACF Plots**

To figure out the order of AR model(p) we will use PACF function. p = the lag value where the PACF chart crosses the upper confidence interval for the first time

To figure out the order of MA model(q) we will use ACF function. q = the lag value where the ACF chart crosses the upper confidence interval for the first time
"""

# Converting the series into pandas data frame
Brazil_df_diff = pd.DataFrame(Brazil_df_diff)
Kenya_df_diff = pd.DataFrame(Kenya_df_diff)

# Creating a loop to plot ACF and PACF plots for all 5 countries
data_list = [USA_df,UK_df, Brazil_df_diff, Kenya_df_diff, India_df]
title_list = ['USA','UK','Brazil','Kenya','India']
for (i,j) in zip(data_list,title_list):
  print('ACF and PACF for %s' %j)
  plot_acf(i[['AverageTemperature']].dropna())
  plt.show()
  plot_pacf(i[['AverageTemperature']].dropna())
  plt.show()

"""**Initial Observations of p and q values. (Final p and q values will be decided based on trial and error and comparing RMSE values)**
*   USA:             p=2 , d=0, q=3
*   UK:              p=2 , d=0, q=3
*   Brazil:          p=2 , d=1, q=2
*   Kenya:           p=2 , d=1, q=2
*   India:           p=2 , d=0, q=3

In an ARIMA model, p and q can have multiple values. So, listed above is only a first observation from the ACF and PACF plots. More accurate values of them will be figured out multiple trials and comparison of RMSE values.

**7) Splitting the data into train (1900-2010) and test(2011-2013)**
"""

# USA
USA_df['Average Temperature'] = USA_df['AverageTemperature'] # this copy of existing variable is taken for cnvenience
#while looping in the next step of modelling
train_USA_df = USA_df[(USA_df.dt < '2011-01-01')]
test_USA_df = USA_df[(USA_df.dt > '2010-12-01')]

# UK
UK_df['Average Temperature'] = UK_df['AverageTemperature']
train_UK_df = UK_df[(UK_df.dt < '2011-01-01')]
test_UK_df = UK_df[(UK_df.dt > '2010-12-01')]
len(test_UK_df['Average Temperature'])

# India
India_df['Average Temperature'] = India_df['AverageTemperature']
train_India_df = India_df[(India_df.dt < '2011-01-01')]
test_India_df = India_df[(India_df.dt > '2010-12-01')]

# brazil
Brazil_df['Average Temperature'] = Brazil_df_diff['AverageTemperature']
train_Brazil_df = Brazil_df[(Brazil_df.dt < '2011-01-01')]
test_Brazil_df = Brazil_df[(Brazil_df.dt > '2010-12-01')]

# Kenya
Kenya_df['Average Temperature'] = Kenya_df_diff['AverageTemperature']
train_Kenya_df = Kenya_df[(Kenya_df.dt < '2011-01-01')]
test_Kenya_df = Kenya_df[(Kenya_df.dt > '2010-12-01')]

"""**8) Fitting ARIMA model on the training data** (using the initial p, q values"""

# Fitting the model on training data
P = [2,2,2,2,2]
D = [0,0,1,1,0]
Q = [3,3,2,2,3]
# P and Q listed above is a result of multiple iterations
data_list = [train_USA_df, train_UK_df, train_Brazil_df, train_Kenya_df, train_India_df]
title_list = ['USA','UK','Brazil','Kenya','India']
ARIMA_models = {}
for (i,j,p,d,q) in zip(data_list,title_list,P,D,Q):
  model = ARIMA(i[['Average Temperature']].dropna(), order=(p, d, q))
  results_ARIMA = model.fit()
  ARIMA_models[j] = results_ARIMA
  plt.figure(figsize= (50,20))
  # print('model plot %s' %j, fontsize = 30)
  plt.plot(i[['Average Temperature']].dropna())
  plt.plot(results_ARIMA.fittedvalues[1:], color='red')
  plt.title('Actual & Model Combined plot for %s' %j , fontsize = 30)

"""**9) Forecasting the average temperature values for the test data**"""

title_list = ['USA','UK','Brazil','Kenya','India']
for j in title_list:
  print('Forecast for %s' %j)
  plot_predict(ARIMA_models[j],start = 1332, end= 1365)

"""**10) Combining the forecast and the test data to create a new dataframe**"""

# Forecasting average temperature
testdata_list = [test_USA_df,test_UK_df,test_Brazil_df, test_Kenya_df,test_India_df]
title_list = ['USA','UK','Brazil','Kenya','India']
ARIMA_forecast = {}
for (i,j) in zip(testdata_list,title_list):
  forecast_results = ARIMA_models[j].forecast(len(i['Average Temperature']))
  ARIMA_forecast[j] = forecast_results
  print('ARIMA Forecast for %s' %j)
  print(forecast_results)

# Converting the forecasted values to list to be added to the original dataframe in the next step
title_list = ['USA','UK','Brazil','Kenya','India']
for j in title_list:
  ARIMA_forecast[j] = ARIMA_forecast[j].tolist()
  print(type(ARIMA_forecast[j]))


# Constructing a new dataframe combining test data and forecasted values
testdata_list = [test_USA_df,test_UK_df,test_Brazil_df, test_Kenya_df,test_India_df]
title_list = ['USA','UK','Brazil','Kenya','India']
for(i,j) in zip(testdata_list,title_list):
  i['predicted'] = ARIMA_forecast[j]
  print('First Five Rows of the modified data for %s' %j)
  print(i.head())

"""**11) Calculating MSE and RMSE for the predictions**"""

testdata_list = [test_USA_df,test_UK_df,test_Brazil_df, test_Kenya_df,test_India_df]
title_list = ['USA','UK','Brazil','Kenya','India']
for (i,j) in zip(testdata_list,title_list):
  MSE = mean_squared_error(i['Average Temperature'].dropna(),i['predicted'][0:len(i['Average Temperature'].dropna())])
  RMSE = np.sqrt(MSE)
  print('values for %s' %j)
  print(MSE)
  print(RMSE)

"""**12)Repeating steps 8 through to 10 for alternate p and q values** (reached these values after multiple iterations)"""

# Fitting the model on training data
P = [2,2,16,14,2]
D = [0,0,1,1,0]
Q = [3,2,2,2,2]
# P and Q listed above is a result of multiple iterations
data_list = [train_USA_df, train_UK_df, train_Brazil_df, train_Kenya_df, train_India_df]
title_list = ['USA','UK','Brazil','Kenya','India']
ARIMA_models = {}
for (i,j,p,d,q) in zip(data_list,title_list,P,D,Q):
  model = ARIMA(i[['Average Temperature']].dropna(), order=(p, d, q))
  results_ARIMA = model.fit()
  ARIMA_models[j] = results_ARIMA
  plt.figure(figsize= (50,20))
  # print('model plot %s' %j, fontsize = 30)
  plt.plot(i[['Average Temperature']].dropna())
  plt.plot(results_ARIMA.fittedvalues[1:], color='red')
  plt.title('Actual & Model Combined plot for %s' %j , fontsize = 30)

"""Visibly better overlap between modelled values and actual values in Brazil and Kenya data"""

title_list = ['USA','UK','Brazil','Kenya','India']
for j in title_list:
  print('Forecast for %s' %j)
  plot_predict(ARIMA_models[j],start = 1332, end= 1365)

"""Much better results in the forecasts. Even the confidence interval is narrower compared to the earlier model"""

# Forecasting average temperature
testdata_list = [test_USA_df,test_UK_df,test_Brazil_df, test_Kenya_df,test_India_df]
title_list = ['USA','UK','Brazil','Kenya','India']
ARIMA_forecast = {}
for (i,j) in zip(testdata_list,title_list):
  forecast_results = ARIMA_models[j].forecast(len(i['Average Temperature']))
  ARIMA_forecast[j] = forecast_results
  print('ARIMA Forecast for %s' %j)
  print(forecast_results)

# Converting the forecasted values to list to be added to the original dataframe in the next step
title_list = ['USA','UK','Brazil','Kenya','India']
for j in title_list:
  ARIMA_forecast[j] = ARIMA_forecast[j].tolist()
  print(type(ARIMA_forecast[j]))


# Constructing a new dataframe combining test data and forecasted values
testdata_list = [test_USA_df,test_UK_df,test_Brazil_df, test_Kenya_df,test_India_df]
title_list = ['USA','UK','Brazil','Kenya','India']
for(i,j) in zip(testdata_list,title_list):
  i['predicted'] = ARIMA_forecast[j]
  print('First Five Rows of the modified data for %s' %j)
  print(i.head())

testdata_list = [test_USA_df,test_UK_df,test_Brazil_df, test_Kenya_df,test_India_df]
title_list = ['USA','UK','Brazil','Kenya','India']
for (i,j) in zip(testdata_list,title_list):
  MSE = mean_squared_error(i['Average Temperature'].dropna(),i['predicted'][0:len(i['Average Temperature'].dropna())])
  RMSE = np.sqrt(MSE)
  print('values for %s' %j)
  print(MSE)
  print(RMSE)

"""It can be easily observed that the RMSE values are much better than that of earlier model

RMSE has the same unit of measure as the variable of interest i.e. Average temperature, which is degree celsius. So, the RMSE values listed above in the results is relatively acceptable.

i.e. for example, the monthly average temperature of Brazil can be forecasted with 0.36 degree celsius accuracy.

It can be observed that the data sets that had gone through differencing shows a better RMSE value than the rest.
"""